{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d0ef26-5f9d-46b1-b0a1-52ddac42f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We knew most of the solutions in the portfolio where its application of robust risk optimization.\n",
    "#Hence, we dont need to use solver or corresponding functions in Scipy/ Numpy Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6136df6-dbb0-4d62-b7dc-d9bd04f8df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import det, inv, eigvals\n",
    "\n",
    "import scipy\n",
    "from scipy.optimize import minimize, LinearConstraint, Bounds\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7a8feb-29f2-4ae1-92cf-58d4bdc941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_i = 0.1\n",
    "sig_ii = 0.3\n",
    "rho_ij = 0.25\n",
    "n = 10\n",
    "\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d0e8e7-a916-4d0e-9ff3-8dc1f900db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.full(n, mu_i)\n",
    "Sigma = np.full((n, n), rho_ij*sig_ii*sig_ii)\n",
    "\n",
    "# Set the diagonal elements to the diagonal value\n",
    "np.fill_diagonal(Sigma, sig_ii*sig_ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664da595-1d50-4a67-8f8e-fb715ae56f36",
   "metadata": {},
   "source": [
    "### Nominal Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "841c678a-408b-4bd0-9b54-fc533a9bc6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "# All weights must be between 0 and 1, so set 0 and 1 as the boundaries.\n",
    "bounds = Bounds(0, 1)\n",
    "\n",
    "# Set the constraint that the sum of weights equals 1.\n",
    "ones_for_sum = np.ones((1, n))\n",
    "linear_constraint = LinearConstraint(ones_for_sum, [1], [1])\n",
    "\n",
    "initial_weights = np.ones(n) / n\n",
    "\n",
    "\n",
    "def objective_nom(a, Sigma): #calculate portfolio risk\n",
    "    return (gamma/2)*np.dot(a, np.dot(a, Sigma))- np.dot(a, mu)\n",
    "\n",
    "# Minimize the risk function using the 'trust-constr' method with linear constraint and bounds.\n",
    "res = minimize(objective_nom, initial_weights, method='trust-constr', constraints=linear_constraint, bounds=bounds, args = (Sigma))\n",
    "a_hat = res.x\n",
    "print(\"Optimal Weights:\", a_hat)\n",
    "\n",
    "# The corresponding relative entropy with this is zero, because we haven't changed the distribution\n",
    "E_Va = objective_nom(a_hat, Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11c457-d21b-4279-abc5-911adca8ae2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "678e3599-05b8-499f-94bf-42cc6d5e15a2",
   "metadata": {},
   "source": [
    "### Worst Case Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9db9d55-0c7d-4adf-8bc5-1ff77436d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan- calculate the entrophy using explicit expression\n",
    "# Calculate the max mean-variance objective using simulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a076ad-e0be-46f8-baef-e5c395c4f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(n)\n",
    "\n",
    "#speciific case for analysis\n",
    "theta_ = 0.2\n",
    "\n",
    "def objective_a_oftheta(a, theta):\n",
    "    term1 = 1 / np.sqrt(det(I - theta * gamma * np.outer(a,a) @ Sigma))\n",
    "    return (1/theta)*np.log(term1) + a.T @ mu\n",
    "\n",
    "def positive_definite_constraint(a, theta):\n",
    "    eigenvalues = eigvals(inv(Sigma) - theta * gamma * np.outer(a,a) )\n",
    "    return np.min(eigenvalues) - 1e-10  # Ensure all eigenvalues are slightly greater than zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c43a856-45f5-46f7-b721-588a87011862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monte-carlo sampling optimization, because the above one does not works\n",
    "n_points = 100000\n",
    "points_on_hyperplane = np.zeros((n_points, 10))\n",
    "\n",
    "for j in range(n_points):\n",
    "    random_numbers = np.random.rand(10)\n",
    "    # Normalize the numbers so their sum is 10\n",
    "    normalized_numbers = random_numbers / random_numbers.sum() \n",
    "\n",
    "    points_on_hyperplane[j] = normalized_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "687df7e0-f4ba-44b1-aeae-6294ef4eb239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:402: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "min_eig_vals = np.apply_along_axis(positive_definite_constraint, axis=1, arr=points_on_hyperplane, theta = theta_)\n",
    "first_positive = np.argmax(min_eig_vals > 0)\n",
    "a0 = points_on_hyperplane[first_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "250bfddd-f00c-4e0c-8dc4-693990c1f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.19063644 0.04372    0.1246579  0.15955892 0.03842917 0.11254156\n",
      " 0.06942072 0.07948461 0.00455775 0.17699293]\n"
     ]
    }
   ],
   "source": [
    "print(first_positive, a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73567587-aa87-4ccb-9c2e-84790ccd64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:598: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  J_transposed[i] = df / dx\n"
     ]
    }
   ],
   "source": [
    "# Initial guess for 'a'\n",
    "#a0 = points_on_hyperplane[1]\n",
    "\n",
    "# Define constraints in the format required by 'minimize'\n",
    "constraints = [\n",
    "    {'type': 'ineq', 'fun': positive_definite_constraint, 'args': (theta_,)},\n",
    "    linear_constraint\n",
    "] \n",
    "\n",
    "# Perform the optimization\n",
    "result = minimize(objective_a_oftheta, a0, method='SLSQP', constraints=constraints, bounds=None, args = (theta_))\n",
    "\n",
    "# Check if the optimization was successful\n",
    "if result.success:\n",
    "    a_star = result.x\n",
    "    print(\"Optimized a:\", a_star)\n",
    "    print(\" Minimum adjective reached at\", np.real(result.fun), \"Not portfolio objective!\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d56f23cd-381a-48d7-be9b-e9ff278641f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Monte Carlo based approximate optimization, if the above method does not work\n",
    "# Segregating out the invalid portfolio vectors\n",
    "indices = np.where(min_eig_vals < 0)[0]\n",
    "# Observation. All the segregated out indices produce nan value in the objective evaluation !\n",
    "\n",
    "objective_val = np.apply_along_axis(objective_a_oftheta, axis=1, arr=points_on_hyperplane, theta = theta_)\n",
    "min_arg = np.nanargmin(objective_val)\n",
    "a_star2 = points_on_hyperplane[min_arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da41658c-5cc0-4998-aa0b-cb22b0c19980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized a: [0.10208299 0.10287419 0.1106846  0.10851892 0.09098528 0.08963041\n",
      " 0.10535194 0.09491924 0.11131909 0.08363333]\n",
      " Minimum adjective reached at 0.11469641424441078\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimized a:\", a_star2)\n",
    "print(\" Minimum adjective reached at\", objective_val[min_arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8c37499-06d2-4396-b568-53e60359129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computaion of entropy, risk_measuremennt\n",
    "#mvo = mean variance objective\n",
    "Sigma_tilda = inv(inv(Sigma) - theta_ * gamma * np.outer(a_star, a_star))\n",
    "\n",
    "entropy = (np.log(det(np.matmul(Sigma, inv(Sigma_tilda)) )) + np.trace(np.matmul(inv(Sigma), Sigma_tilda) - I))/2\n",
    "\n",
    "RPs_nominal = objective_nom(a_star, Sigma)\n",
    "NPs_worstcase = -np.dot(a_hat, mu) + (gamma/2)* np.dot(np.matmul(a_hat, Sigma_tilda), a_hat)\n",
    "RPs_worstcase = -np.dot(a_star, mu) + (gamma/2)* np.dot(np.matmul(a_star, Sigma_tilda), a_star)\n",
    "\n",
    "risk_meas2 = -np.dot(a_star, mu) + (gamma/2)*np.dot(a_star, np.dot(a_star, Sigma_tilda))\n",
    "# Both of them are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b219a387-83bc-4c31-beb9-58bbb57049dd",
   "metadata": {},
   "source": [
    "Scipy optimize based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22442646-c2bd-475a-ae70-694a3c97ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to find a feasible starting point-\n",
    "n_points = 1000\n",
    "checking_points = np.zeros((n_points, 10))\n",
    "\n",
    "for j in range(n_points):\n",
    "    p = np.zeros(10)\n",
    "    # Generate random values for the first 9 coordinates\n",
    "    curr_sum = 0\n",
    "    for i in range(9):\n",
    "        p[i] = np.random.uniform(0, 1 - curr_sum)\n",
    "        curr_sum += p[i]\n",
    "    p[9] = 1 - curr_sum\n",
    "\n",
    "    checking_points[j] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "602c64ed-ae5a-4a7a-b15e-f8c47baaec7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n",
      "Optimized a: [0.10003899 0.09997648 0.10001044 0.10002628 0.09997312 0.10000523\n",
      " 0.09998676 0.09999098 0.09995871 0.10003302]\n",
      " Minimum adjective reached at 0.11466794592169285 Not portfolio objective!\n"
     ]
    }
   ],
   "source": [
    "results_ = {}\n",
    "thetas = (np.exp(np.linspace(0, 0.4)) - 1)[1:]\n",
    "for theta in thetas:\n",
    "    # Calculate worst-case covariance matrix\n",
    "    Sigma_worst_case = inv(inv(Sigma) - theta * gamma * np.outer(a_hat, a_hat))\n",
    "    # Calculate performance in the worst-case model\n",
    "    NP_worst_case = objective_nom(a_hat, Sigma_worst_case)\n",
    "    \n",
    "    min_eig_vals = np.apply_along_axis(positive_definite_constraint, axis=1, arr=points_on_hyperplane, theta = theta_)\n",
    "    first_positive = np.argmax(min_eig_vals > 0)\n",
    "    a0 = points_on_hyperplane[first_positive]\n",
    "\n",
    "    constraints = [\n",
    "    {'type': 'ineq', 'fun': positive_definite_constraint, 'args': (theta_,)},\n",
    "    linear_constraint\n",
    "    ] \n",
    "    \n",
    "    # Perform the optimization\n",
    "    result = minimize(objective_a_oftheta, a0, method='SLSQP', constraints=constraints, bounds=None, args = (theta_))\n",
    "    \n",
    "    # Check if the optimization was successful\n",
    "    if result.success:\n",
    "        a_star = result.x\n",
    "        print(\"Optimized a:\", a_star)\n",
    "        print(\" Minimum adjective reached at\", np.real(result.fun), \"Not portfolio objective!\")\n",
    "    else:\n",
    "        print(\"Optimization failed:\", result.message)\n",
    "    \n",
    "    #computaion of entropy, risk-measurement\n",
    "    Sigma_tilda = inv(inv(Sigma) - theta * gamma * np.outer(a_star, a_star))\n",
    "    \n",
    "    entropy = (np.log(det(np.matmul(Sigma, inv(Sigma_tilda)) )) + np.trace(np.matmul(inv(Sigma), Sigma_tilda) - I))/2\n",
    "    \n",
    "    RPs_nominal = objective_nom(a_star, Sigma)\n",
    "                    \n",
    "    #NPs_worstcase = objective_nom(a_hat, Sigma_tilda)\n",
    "    RPs_worstcase = objective_nom(a_star, Sigma_tilda)\n",
    "    \n",
    "    results_[theta] = (entropy, RPs_nominal, NP_worst_case, RPs_worstcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a247c47-f0aa-4e79-aadd-fc97f33f2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a list of tuples\n",
    "data_list = [(key, *value) for key, value in results_.items()]\n",
    "\n",
    "# Create a DataFrame\n",
    "df_wc = pd.DataFrame(data_list, columns=['Theta', 'Entropy', 'RPs_nominal', 'NPs_worstcase', 'RPs_worstcase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49f365-ca3a-4507-bf50-58c6b8c7c7c6",
   "metadata": {},
   "source": [
    "Using Monte carlo sample based approximate optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afe7ad7b-32f1-4a9a-9b7b-9995ada7edbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prith\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:402: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "results2_ = {}\n",
    "thetas = (np.exp(np.linspace(0, 2)) - 1)[1:]\n",
    "for theta in thetas:\n",
    "\n",
    "    def objective_t(a):\n",
    "        return objective(theta, a)\n",
    "        \n",
    "    def positive_definite_constraint_t(a):\n",
    "        return positive_definite_constraint(theta, a)\n",
    "    \n",
    "    min_eig_vals = np.apply_along_axis(positive_definite_constraint_t, axis=1, arr=points_on_hyperplane)\n",
    "    \n",
    "    no_invalid = np.sum(np.real(min_eig_vals) < 0)\n",
    "    if (no_invalid):\n",
    "        print(\"No of invalid points for theta=\", theta, \"hyperplane:\", no_invalid)\n",
    "    \n",
    "    objective_val = np.apply_along_axis(objective_t, axis=1, arr=points_on_hyperplane)\n",
    "    min_arg = np.nanargmin(objective_val)\n",
    "    a_star = points_on_hyperplane[min_arg]\n",
    "    \n",
    "    #computaion of entropy, \n",
    "    Sigma_tilda = inv(inv(Sigma) - theta * gamma * np.outer(a_star, a_star))\n",
    "    \n",
    "    entropy = (np.log(det(np.matmul(Sigma, inv(Sigma_tilda)) )) + np.trace(np.matmul(inv(Sigma), Sigma_tilda) - I))/2\n",
    "    \n",
    "    RPs_nominal = objective_nom(a_star)\n",
    "    NPs_worstcase = -np.dot(a_hat, mu) + (gamma/2)* np.dot(np.matmul(a_hat, Sigma_tilda), a_hat)\n",
    "    RPs_worstcase = -np.dot(a_star, mu) + (gamma/2)* np.dot(np.matmul(a_star, Sigma_tilda), a_star)\n",
    "    \n",
    "    results2_[theta] = (entropy, RPs_nominal, NPs_worstcase, RPs_worstcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "300d3f31-7fa3-4cfb-9d5d-d9a9b686c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a list of tuples\n",
    "data_list = [(key, *value) for key, value in results2_.items()]\n",
    "\n",
    "# Create a DataFrame\n",
    "df_wc1 = pd.DataFrame(data_list, columns=['Theta', 'Entropy', 'Risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f2d8e45-dbd1-4ee2-a19a-a880d8d47c32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theta</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.664535e-15</td>\n",
       "      <td>-0.072834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041661</td>\n",
       "      <td>4.001459e-07</td>\n",
       "      <td>-0.084810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085057</td>\n",
       "      <td>1.670896e-06</td>\n",
       "      <td>-0.084790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130261</td>\n",
       "      <td>3.926053e-06</td>\n",
       "      <td>-0.084769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177349</td>\n",
       "      <td>7.291430e-06</td>\n",
       "      <td>-0.084747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.226398</td>\n",
       "      <td>1.190606e-05</td>\n",
       "      <td>-0.084724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277491</td>\n",
       "      <td>1.792353e-05</td>\n",
       "      <td>-0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.330712</td>\n",
       "      <td>2.551346e-05</td>\n",
       "      <td>-0.084675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.386151</td>\n",
       "      <td>3.486314e-05</td>\n",
       "      <td>-0.084649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.443899</td>\n",
       "      <td>4.617929e-05</td>\n",
       "      <td>-0.084622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.504053</td>\n",
       "      <td>5.969009e-05</td>\n",
       "      <td>-0.084593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.566713</td>\n",
       "      <td>7.564736e-05</td>\n",
       "      <td>-0.084564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.631983</td>\n",
       "      <td>9.432898e-05</td>\n",
       "      <td>-0.084532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.699973</td>\n",
       "      <td>1.160416e-04</td>\n",
       "      <td>-0.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.770795</td>\n",
       "      <td>1.411235e-04</td>\n",
       "      <td>-0.084466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.844568</td>\n",
       "      <td>1.699482e-04</td>\n",
       "      <td>-0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.921414</td>\n",
       "      <td>2.029276e-04</td>\n",
       "      <td>-0.084393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.001461</td>\n",
       "      <td>2.405167e-04</td>\n",
       "      <td>-0.084354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.084844</td>\n",
       "      <td>2.832175e-04</td>\n",
       "      <td>-0.084313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.171700</td>\n",
       "      <td>3.315844e-04</td>\n",
       "      <td>-0.084270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.262175</td>\n",
       "      <td>3.862297e-04</td>\n",
       "      <td>-0.084225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.356418</td>\n",
       "      <td>4.478295e-04</td>\n",
       "      <td>-0.084178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.454589</td>\n",
       "      <td>5.171313e-04</td>\n",
       "      <td>-0.084128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.556849</td>\n",
       "      <td>5.949612e-04</td>\n",
       "      <td>-0.084077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.663369</td>\n",
       "      <td>6.822327e-04</td>\n",
       "      <td>-0.084023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.774327</td>\n",
       "      <td>7.799563e-04</td>\n",
       "      <td>-0.083966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.889907</td>\n",
       "      <td>8.892505e-04</td>\n",
       "      <td>-0.083906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.010303</td>\n",
       "      <td>1.011354e-03</td>\n",
       "      <td>-0.083843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.135715</td>\n",
       "      <td>1.147639e-03</td>\n",
       "      <td>-0.083778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.266351</td>\n",
       "      <td>1.299626e-03</td>\n",
       "      <td>-0.083709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.402430</td>\n",
       "      <td>1.469004e-03</td>\n",
       "      <td>-0.083636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.544178</td>\n",
       "      <td>1.657645e-03</td>\n",
       "      <td>-0.083560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.691831</td>\n",
       "      <td>1.867630e-03</td>\n",
       "      <td>-0.083480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.845635</td>\n",
       "      <td>2.101273e-03</td>\n",
       "      <td>-0.083395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.005847</td>\n",
       "      <td>2.361147e-03</td>\n",
       "      <td>-0.083306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.172734</td>\n",
       "      <td>2.650120e-03</td>\n",
       "      <td>-0.083213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.346573</td>\n",
       "      <td>2.971387e-03</td>\n",
       "      <td>-0.083114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.527655</td>\n",
       "      <td>3.328513e-03</td>\n",
       "      <td>-0.083010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.716280</td>\n",
       "      <td>3.725481e-03</td>\n",
       "      <td>-0.082901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.912764</td>\n",
       "      <td>4.166746e-03</td>\n",
       "      <td>-0.082785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.117434</td>\n",
       "      <td>4.657295e-03</td>\n",
       "      <td>-0.082663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.330630</td>\n",
       "      <td>5.202718e-03</td>\n",
       "      <td>-0.082534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.552708</td>\n",
       "      <td>5.809293e-03</td>\n",
       "      <td>-0.082397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.784038</td>\n",
       "      <td>6.484077e-03</td>\n",
       "      <td>-0.082253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.025005</td>\n",
       "      <td>7.235018e-03</td>\n",
       "      <td>-0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.276012</td>\n",
       "      <td>8.071078e-03</td>\n",
       "      <td>-0.081937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.537475</td>\n",
       "      <td>9.002385e-03</td>\n",
       "      <td>-0.081765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.809831</td>\n",
       "      <td>1.004040e-02</td>\n",
       "      <td>-0.081582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6.093534</td>\n",
       "      <td>1.119813e-02</td>\n",
       "      <td>-0.081388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6.389056</td>\n",
       "      <td>1.249035e-02</td>\n",
       "      <td>-0.081181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Theta       Entropy      Risk\n",
       "0   0.000000  2.664535e-15 -0.072834\n",
       "1   0.041661  4.001459e-07 -0.084810\n",
       "2   0.085057  1.670896e-06 -0.084790\n",
       "3   0.130261  3.926053e-06 -0.084769\n",
       "4   0.177349  7.291430e-06 -0.084747\n",
       "5   0.226398  1.190606e-05 -0.084724\n",
       "6   0.277491  1.792353e-05 -0.084700\n",
       "7   0.330712  2.551346e-05 -0.084675\n",
       "8   0.386151  3.486314e-05 -0.084649\n",
       "9   0.443899  4.617929e-05 -0.084622\n",
       "10  0.504053  5.969009e-05 -0.084593\n",
       "11  0.566713  7.564736e-05 -0.084564\n",
       "12  0.631983  9.432898e-05 -0.084532\n",
       "13  0.699973  1.160416e-04 -0.084500\n",
       "14  0.770795  1.411235e-04 -0.084466\n",
       "15  0.844568  1.699482e-04 -0.084430\n",
       "16  0.921414  2.029276e-04 -0.084393\n",
       "17  1.001461  2.405167e-04 -0.084354\n",
       "18  1.084844  2.832175e-04 -0.084313\n",
       "19  1.171700  3.315844e-04 -0.084270\n",
       "20  1.262175  3.862297e-04 -0.084225\n",
       "21  1.356418  4.478295e-04 -0.084178\n",
       "22  1.454589  5.171313e-04 -0.084128\n",
       "23  1.556849  5.949612e-04 -0.084077\n",
       "24  1.663369  6.822327e-04 -0.084023\n",
       "25  1.774327  7.799563e-04 -0.083966\n",
       "26  1.889907  8.892505e-04 -0.083906\n",
       "27  2.010303  1.011354e-03 -0.083843\n",
       "28  2.135715  1.147639e-03 -0.083778\n",
       "29  2.266351  1.299626e-03 -0.083709\n",
       "30  2.402430  1.469004e-03 -0.083636\n",
       "31  2.544178  1.657645e-03 -0.083560\n",
       "32  2.691831  1.867630e-03 -0.083480\n",
       "33  2.845635  2.101273e-03 -0.083395\n",
       "34  3.005847  2.361147e-03 -0.083306\n",
       "35  3.172734  2.650120e-03 -0.083213\n",
       "36  3.346573  2.971387e-03 -0.083114\n",
       "37  3.527655  3.328513e-03 -0.083010\n",
       "38  3.716280  3.725481e-03 -0.082901\n",
       "39  3.912764  4.166746e-03 -0.082785\n",
       "40  4.117434  4.657295e-03 -0.082663\n",
       "41  4.330630  5.202718e-03 -0.082534\n",
       "42  4.552708  5.809293e-03 -0.082397\n",
       "43  4.784038  6.484077e-03 -0.082253\n",
       "44  5.025005  7.235018e-03 -0.082100\n",
       "45  5.276012  8.071078e-03 -0.081937\n",
       "46  5.537475  9.002385e-03 -0.081765\n",
       "47  5.809831  1.004040e-02 -0.081582\n",
       "48  6.093534  1.119813e-02 -0.081388\n",
       "49  6.389056  1.249035e-02 -0.081181"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be004c72-e597-4d20-8f31-a9685500786e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Theta</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>RPs_nominal</th>\n",
       "      <th>NPs_worstcase</th>\n",
       "      <th>RPs_worstcase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>1.437494e-08</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085371</td>\n",
       "      <td>-0.085371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016461</td>\n",
       "      <td>5.799073e-08</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085368</td>\n",
       "      <td>-0.085368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024792</td>\n",
       "      <td>1.315951e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085364</td>\n",
       "      <td>-0.085364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033192</td>\n",
       "      <td>2.359509e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085361</td>\n",
       "      <td>-0.085361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041661</td>\n",
       "      <td>3.718367e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085357</td>\n",
       "      <td>-0.085357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050199</td>\n",
       "      <td>5.400466e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085353</td>\n",
       "      <td>-0.085353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.058807</td>\n",
       "      <td>7.413913e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085350</td>\n",
       "      <td>-0.085350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.067486</td>\n",
       "      <td>9.766975e-07</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085346</td>\n",
       "      <td>-0.085346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.076236</td>\n",
       "      <td>1.246809e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085342</td>\n",
       "      <td>-0.085342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.085057</td>\n",
       "      <td>1.552586e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085339</td>\n",
       "      <td>-0.085339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.093951</td>\n",
       "      <td>1.894907e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085335</td>\n",
       "      <td>-0.085335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.102918</td>\n",
       "      <td>2.274668e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.085331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.111958</td>\n",
       "      <td>2.692783e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085327</td>\n",
       "      <td>-0.085327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.121072</td>\n",
       "      <td>3.150184e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085323</td>\n",
       "      <td>-0.085323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.130261</td>\n",
       "      <td>3.647823e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085319</td>\n",
       "      <td>-0.085319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.139526</td>\n",
       "      <td>4.186670e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085315</td>\n",
       "      <td>-0.085315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.148866</td>\n",
       "      <td>4.767714e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085311</td>\n",
       "      <td>-0.085311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.158283</td>\n",
       "      <td>5.391966e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085307</td>\n",
       "      <td>-0.085307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.167777</td>\n",
       "      <td>6.060456e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085303</td>\n",
       "      <td>-0.085303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.177349</td>\n",
       "      <td>6.774235e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085299</td>\n",
       "      <td>-0.085299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.186999</td>\n",
       "      <td>7.534375e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085295</td>\n",
       "      <td>-0.085295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.196729</td>\n",
       "      <td>8.341969e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>-0.085290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.206538</td>\n",
       "      <td>9.198132e-06</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085286</td>\n",
       "      <td>-0.085286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.216428</td>\n",
       "      <td>1.010400e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085282</td>\n",
       "      <td>-0.085282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.226398</td>\n",
       "      <td>1.106074e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085278</td>\n",
       "      <td>-0.085278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.236451</td>\n",
       "      <td>1.206953e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085273</td>\n",
       "      <td>-0.085273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.246585</td>\n",
       "      <td>1.313158e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085269</td>\n",
       "      <td>-0.085269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.256803</td>\n",
       "      <td>1.424812e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085264</td>\n",
       "      <td>-0.085264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.267105</td>\n",
       "      <td>1.542041e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085260</td>\n",
       "      <td>-0.085260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.277491</td>\n",
       "      <td>1.664972e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085255</td>\n",
       "      <td>-0.085255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.287962</td>\n",
       "      <td>1.793737e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085251</td>\n",
       "      <td>-0.085251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.298519</td>\n",
       "      <td>1.928469e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085246</td>\n",
       "      <td>-0.085246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.309163</td>\n",
       "      <td>2.069303e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085242</td>\n",
       "      <td>-0.085242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.319893</td>\n",
       "      <td>2.216379e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085237</td>\n",
       "      <td>-0.085237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.330712</td>\n",
       "      <td>2.369838e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085232</td>\n",
       "      <td>-0.085232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.341620</td>\n",
       "      <td>2.529823e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085227</td>\n",
       "      <td>-0.085227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.352616</td>\n",
       "      <td>2.696483e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085223</td>\n",
       "      <td>-0.085223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.363703</td>\n",
       "      <td>2.869967e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085218</td>\n",
       "      <td>-0.085218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.374881</td>\n",
       "      <td>3.050428e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085213</td>\n",
       "      <td>-0.085213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.386151</td>\n",
       "      <td>3.238023e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085208</td>\n",
       "      <td>-0.085208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.397513</td>\n",
       "      <td>3.432910e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085203</td>\n",
       "      <td>-0.085203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.408967</td>\n",
       "      <td>3.635251e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085198</td>\n",
       "      <td>-0.085198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.420516</td>\n",
       "      <td>3.845213e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085193</td>\n",
       "      <td>-0.085193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.432160</td>\n",
       "      <td>4.062964e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085188</td>\n",
       "      <td>-0.085188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.443899</td>\n",
       "      <td>4.288677e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085183</td>\n",
       "      <td>-0.085183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.455734</td>\n",
       "      <td>4.522526e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085177</td>\n",
       "      <td>-0.085177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.467666</td>\n",
       "      <td>4.764691e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085172</td>\n",
       "      <td>-0.085172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.479696</td>\n",
       "      <td>5.015355e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085167</td>\n",
       "      <td>-0.085167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.491825</td>\n",
       "      <td>5.274704e-05</td>\n",
       "      <td>-0.085375</td>\n",
       "      <td>-0.085162</td>\n",
       "      <td>-0.085162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Theta       Entropy  RPs_nominal  NPs_worstcase  RPs_worstcase\n",
       "0   0.008197  1.437494e-08    -0.085375      -0.085371      -0.085371\n",
       "1   0.016461  5.799073e-08    -0.085375      -0.085368      -0.085368\n",
       "2   0.024792  1.315951e-07    -0.085375      -0.085364      -0.085364\n",
       "3   0.033192  2.359509e-07    -0.085375      -0.085361      -0.085361\n",
       "4   0.041661  3.718367e-07    -0.085375      -0.085357      -0.085357\n",
       "5   0.050199  5.400466e-07    -0.085375      -0.085353      -0.085353\n",
       "6   0.058807  7.413913e-07    -0.085375      -0.085350      -0.085350\n",
       "7   0.067486  9.766975e-07    -0.085375      -0.085346      -0.085346\n",
       "8   0.076236  1.246809e-06    -0.085375      -0.085342      -0.085342\n",
       "9   0.085057  1.552586e-06    -0.085375      -0.085339      -0.085339\n",
       "10  0.093951  1.894907e-06    -0.085375      -0.085335      -0.085335\n",
       "11  0.102918  2.274668e-06    -0.085375      -0.085331      -0.085331\n",
       "12  0.111958  2.692783e-06    -0.085375      -0.085327      -0.085327\n",
       "13  0.121072  3.150184e-06    -0.085375      -0.085323      -0.085323\n",
       "14  0.130261  3.647823e-06    -0.085375      -0.085319      -0.085319\n",
       "15  0.139526  4.186670e-06    -0.085375      -0.085315      -0.085315\n",
       "16  0.148866  4.767714e-06    -0.085375      -0.085311      -0.085311\n",
       "17  0.158283  5.391966e-06    -0.085375      -0.085307      -0.085307\n",
       "18  0.167777  6.060456e-06    -0.085375      -0.085303      -0.085303\n",
       "19  0.177349  6.774235e-06    -0.085375      -0.085299      -0.085299\n",
       "20  0.186999  7.534375e-06    -0.085375      -0.085295      -0.085295\n",
       "21  0.196729  8.341969e-06    -0.085375      -0.085290      -0.085290\n",
       "22  0.206538  9.198132e-06    -0.085375      -0.085286      -0.085286\n",
       "23  0.216428  1.010400e-05    -0.085375      -0.085282      -0.085282\n",
       "24  0.226398  1.106074e-05    -0.085375      -0.085278      -0.085278\n",
       "25  0.236451  1.206953e-05    -0.085375      -0.085273      -0.085273\n",
       "26  0.246585  1.313158e-05    -0.085375      -0.085269      -0.085269\n",
       "27  0.256803  1.424812e-05    -0.085375      -0.085264      -0.085264\n",
       "28  0.267105  1.542041e-05    -0.085375      -0.085260      -0.085260\n",
       "29  0.277491  1.664972e-05    -0.085375      -0.085255      -0.085255\n",
       "30  0.287962  1.793737e-05    -0.085375      -0.085251      -0.085251\n",
       "31  0.298519  1.928469e-05    -0.085375      -0.085246      -0.085246\n",
       "32  0.309163  2.069303e-05    -0.085375      -0.085242      -0.085242\n",
       "33  0.319893  2.216379e-05    -0.085375      -0.085237      -0.085237\n",
       "34  0.330712  2.369838e-05    -0.085375      -0.085232      -0.085232\n",
       "35  0.341620  2.529823e-05    -0.085375      -0.085227      -0.085227\n",
       "36  0.352616  2.696483e-05    -0.085375      -0.085223      -0.085223\n",
       "37  0.363703  2.869967e-05    -0.085375      -0.085218      -0.085218\n",
       "38  0.374881  3.050428e-05    -0.085375      -0.085213      -0.085213\n",
       "39  0.386151  3.238023e-05    -0.085375      -0.085208      -0.085208\n",
       "40  0.397513  3.432910e-05    -0.085375      -0.085203      -0.085203\n",
       "41  0.408967  3.635251e-05    -0.085375      -0.085198      -0.085198\n",
       "42  0.420516  3.845213e-05    -0.085375      -0.085193      -0.085193\n",
       "43  0.432160  4.062964e-05    -0.085375      -0.085188      -0.085188\n",
       "44  0.443899  4.288677e-05    -0.085375      -0.085183      -0.085183\n",
       "45  0.455734  4.522526e-05    -0.085375      -0.085177      -0.085177\n",
       "46  0.467666  4.764691e-05    -0.085375      -0.085172      -0.085172\n",
       "47  0.479696  5.015355e-05    -0.085375      -0.085167      -0.085167\n",
       "48  0.491825  5.274704e-05    -0.085375      -0.085162      -0.085162"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f4ba3ed-80b7-4804-b8a1-a54237271137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "df_wc.plot(ax = ax, x='Entropy',y='RPs_nominal', linestyle=(0, (5, 5)), linewidth=1.5, color='green')\n",
    "ax.axhline(y = E_Va, color = 'b', linestyle = (0, (3, 5, 1, 5)))\n",
    "df_wc.plot(ax = ax, x='Entropy',y='RPs_worstcase', linestyle='dotted', linewidth=1.5, color='orange')\n",
    "df_wc.plot(ax = ax, x='Entropy',y='NPs_worstcase', linestyle='solid', linewidth=1.5, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e872682-c45b-4576-8073-6363c08c6c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
